{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacked Auto Encoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnipun/ColabProjects/blob/master/Stacked_Auto_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7zhFS-KzWBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTYxe2O0Y94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional denoising autoencoder layer for stacked autoencoders.\n",
        "    This module is automatically trained when in model.training is True.\n",
        "    Args:\n",
        "        input_size: The number of features in the input\n",
        "        output_size: The number of features to output\n",
        "        stride: Stride of the convolutional layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encode = nn.Sequential(\n",
        "            nn.Linear(input_size,hidden_size)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decode = nn.Sequential(\n",
        "            nn.Linear(hidden_size,input_size)\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Train each autoencoder individually\n",
        "        x = x.detach()\n",
        "        # Add noise, but use the original lossless input as the target.\n",
        "        x_noisy = x * (Variable(x.data.new(x.size()).normal_(0, 0.1)) > -.1).type_as(x)\n",
        "        y = self.encode(x_noisy)\n",
        "\n",
        "        if self.training:\n",
        "            x_reconstruct = self.deocde(y)\n",
        "            loss = self.criterion(x_reconstruct, Variable(x.data, requires_grad=False))\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "        return y.detach()\n",
        "\n",
        "    def reconstruct(self, x):\n",
        "        return self.backward_pass(x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}