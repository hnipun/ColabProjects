{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacked Auto Encoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnipun/ColabProjects/blob/master/Stacked_Auto_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7zhFS-KzWBf",
        "colab_type": "code",
        "outputId": "6681f272-6dbd-4639-ce66-e0d790b91ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Checks for the availability of GPU \n",
        "if torch.cuda.is_available():\n",
        "    print(\"working on gpu!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No gpu! only cpu ;)\")\n",
        "    device = 'cpu'\n",
        "    \n",
        "if device == 'cpu':    \n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "elif device == 'cuda':\n",
        "    random.seed(0)\n",
        "    np.random.seed(0)\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = '0'"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No gpu! only cpu ;)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGqlBNJl5hxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_img(x):\n",
        "    x = x.view(x.size(0), 1, 32, 32)\n",
        "    return x\n",
        "\n",
        "def flatten_img(x):\n",
        "    x = x.view(x.size(0), 1*32*32)\n",
        "    return x\n",
        "\n",
        "def get_data_indices(dataset, fine_tune_idx, labels_per_class = 10):\n",
        "    indices = []\n",
        "    count = {}\n",
        "    for i in range(10):\n",
        "      count[i] = 0\n",
        "    \n",
        "    for index in fine_tune_idx:\n",
        "        image, label = dataset[index]\n",
        "        \n",
        "        if count[label] < labels_per_class:\n",
        "          count[label] += 1\n",
        "          indices.append(index)\n",
        "        continue\n",
        "\n",
        "    return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTYxe2O0Y94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional denoising autoencoder layer for stacked autoencoders.\n",
        "    This module is automatically trained when in model.training is True.\n",
        "    Args:\n",
        "        input_size: The number of features in the input\n",
        "        output_size: The number of features to output\n",
        "        stride: Stride of the convolutional layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encode = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decode = nn.Sequential(\n",
        "            nn.Linear(hidden_size, input_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Train each autoencoder individually\n",
        "        x = x.detach()\n",
        "        # Add noise, but use the original lossless input as the target.\n",
        "        y = self.encode(x)\n",
        "\n",
        "        if self.training:\n",
        "            x_reconstruct = self.decode(y)\n",
        "            loss = self.criterion(x_reconstruct, Variable(x.data, requires_grad=False))\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "        return y.detach()\n",
        "\n",
        "    def reconstruct(self, x):\n",
        "        return self.decode(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKykUhpOuSzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackedAutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A stacked autoencoder made from the convolutional denoising autoencoders above.\n",
        "    Each autoencoder is trained independently and at the same time.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(StackedAutoEncoder, self).__init__()\n",
        "\n",
        "        self.ae1 = AutoEncoder(1024, 1000)\n",
        "        self.ae2 = AutoEncoder(1000, 800)\n",
        "        self.ae3 = AutoEncoder(800, 500)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x  = flatten_img(x)\n",
        "        a1 = self.ae1(x)\n",
        "        a2 = self.ae2(a1)\n",
        "        a3 = self.ae3(a2)\n",
        "\n",
        "        if self.training:\n",
        "            return a3\n",
        "        else:\n",
        "            return a3, self.reconstruct(a3)\n",
        "\n",
        "    def reconstruct(self, x):\n",
        "            a2_reconstruct = self.ae3.reconstruct(x)\n",
        "            a1_reconstruct = self.ae2.reconstruct(a2_reconstruct)\n",
        "            x_reconstruct = self.ae1.reconstruct(a1_reconstruct)\n",
        "            return x_reconstruct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WTanOTr_QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes, stacked_encoder):\n",
        "            super(Classifier, self).__init__()\n",
        "            \n",
        "            self.features = stacked_encoder\n",
        "            self.linear_layers = nn.Sequential(nn.Linear(500, 10))\n",
        "          \n",
        "    def forward(self, x):\n",
        "      if self.training:\n",
        "            x    = self.features(x)\n",
        "      else:\n",
        "            x, _ = self.features(x)\n",
        "      x  = self.linear_layers(x)\n",
        "            \n",
        "      return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PQe4JP6g0jO",
        "colab_type": "code",
        "outputId": "43232906-52d6-4f48-e64f-dda89839038e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if not os.path.exists('./imgs'):\n",
        "    os.mkdir('./imgs')\n",
        "    \n",
        "batch_size = 128\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0, hue=0),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "dataset = CIFAR10('../data/cifar10/', train=True, transform=img_transform, download=True)\n",
        "\n",
        "num_dataset = len(dataset)\n",
        "indices = list(range(num_dataset))\n",
        "np.random.shuffle(indices)\n",
        "train_split = int(np.floor(0.2 * num_dataset))\n",
        "test_split = int(np.floor(0.1 * num_dataset)) + train_split\n",
        "train_idx, test_idx, fine_tune_idx = indices[:train_split], indices[train_split:test_split], indices[test_split:]\n",
        "\n",
        "fine_tune_idx_10 = get_data_indices(dataset, fine_tune_idx, 10)\n",
        "fine_tune_idx_100 = get_data_indices(dataset, fine_tune_idx, 100)\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "finetune_sampler_10 = SubsetRandomSampler(fine_tune_idx_10)\n",
        "finetune_sampler_100 = SubsetRandomSampler(fine_tune_idx_100)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, drop_last=False)\n",
        "finetune_loader_10 = DataLoader(dataset, batch_size=batch_size, sampler=finetune_sampler_10, drop_last=False)\n",
        "finetune_loader_100 = DataLoader(dataset, batch_size=batch_size, sampler=finetune_sampler_100, drop_last=False)\n",
        "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, drop_last=False)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcSPfKNwJZ1",
        "colab_type": "code",
        "outputId": "a7588ee0-dda1-4b2c-9039-fdd6dc4635af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "loss_ = []\n",
        "mean_ = []\n",
        "sparsity_ = []\n",
        "max_ = []\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "model = StackedAutoEncoder().to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_time = time.time()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        img, target = data\n",
        "        target = Variable(target).to(device)\n",
        "        img = Variable(img).to(device)\n",
        "        features = model(img).detach()\n",
        "\n",
        "    total_time = time.time() - total_time\n",
        "\n",
        "    model.eval()\n",
        "    img, _ = data\n",
        "    img = Variable(img)\n",
        "    features, x_reconstructed = model(img)\n",
        "    reconstruction_loss = torch.mean((x_reconstructed.data - flatten_img(img).data)**2)\n",
        "    loss_.append(reconstruction_loss)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Saving epoch {}\".format(epoch))\n",
        "        orig = to_img(img.cpu().data)\n",
        "        save_image(orig, './imgs/orig_{}.png'.format(epoch))\n",
        "        pic = to_img(x_reconstructed.cpu().data)\n",
        "        save_image(pic, './imgs/reconstruction_{}.png'.format(epoch))\n",
        "    \n",
        "    mean = torch.mean(features.data)\n",
        "    sparsity = torch.sum(features.data == 0.0)*100 / features.data.numel()\n",
        "    max_value = torch.max(features.data)\n",
        "    mean_.append(mean)\n",
        "    sparsity_.append(sparsity)\n",
        "    max_.append(max_value)\n",
        "\n",
        "    print(\"Epoch {} complete\\tTime: {:.4f}s\\t\\tLoss: {:.4f}\".format(epoch, total_time, reconstruction_loss))\n",
        "    print(\"Feature Statistics\\tMean: {:.4f}\\t\\tMax: {:.4f}\\t\\tSparsity: {:.4f}%\".format(\n",
        "        mean, max_value, sparsity))\n",
        "    print(\"=\"*80)\n",
        "\n",
        "torch.save(model.state_dict(), './CDAE.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving epoch 0\n",
            "Epoch 0 complete\tTime: 9.7895s\t\tLoss: 0.2898\n",
            "Feature Statistics\tMean: 0.0990\t\tMax: 1.3806\t\tSparsity: 53.0000%\n",
            "================================================================================\n",
            "Epoch 1 complete\tTime: 9.7704s\t\tLoss: 0.1447\n",
            "Feature Statistics\tMean: 0.1720\t\tMax: 2.4031\t\tSparsity: 57.0000%\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz9Lcn6WvqXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(loader, images_per_class = 10, epochs=100):\n",
        "  classifier = Classifier(num_classes = 10, stacked_encoder = model)\n",
        "  classifier = classifier.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "  loss_ = []\n",
        "  for epoch in range(epochs):\n",
        "          # Iterate through the batches in the data\n",
        "          training_loss = 0.0\n",
        "          classifier.train()\n",
        "          # for (images,labels)  in trange(train_loader, leave=False):\n",
        "          for (images,labels), in zip(loader):\n",
        "              ## Move the images to the device\n",
        "              images = images.to(device)\n",
        "              ## Move the labels to the device\n",
        "              labels = labels.to(device)\n",
        "              ## Get the output of the model by passing input to the model\n",
        "              output_train = classifier(images)\n",
        "              ## Find the loss of the input batch by passing output & ground truth labels to the criterion\n",
        "              loss_train = criterion(output_train, labels)\n",
        "              training_loss += loss_train.item()\n",
        "              ## clear the gradients\n",
        "              optimizer.zero_grad()\n",
        "              ## compute the gradients by backpropagating through the computational graph.\n",
        "              loss_train.backward()\n",
        "              ## update the parameters \n",
        "              optimizer.step()\n",
        "              loss_.append(training_loss)\n",
        "\n",
        "          print(\"Epoch {} complete\\tTime: {:.4f}s\\t\\tLoss: {:.4f}\".format(epoch, total_time, training_loss))\n",
        "          print(\"=\"*80)\n",
        "\n",
        "  return classifier, loss_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b7ichBa0sB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Testing Loop\n",
        "def count_correct(preds, labels):\n",
        "  count = 0\n",
        "  for pred, label in zip(preds, labels):\n",
        "    if pred == label:\n",
        "      count += 1\n",
        "  return count\n",
        "\n",
        "def test_model(classifier):\n",
        "    '''\n",
        "    A function to test the trained model on the test dataset and print the accuracy.\n",
        "    \n",
        "    Inputs:\n",
        "        model: Trained model.\n",
        "        \n",
        "    outputs:\n",
        "        None. Prints the accuracy.\n",
        "    '''\n",
        "    classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0.0\n",
        "        total_samples = 0.0\n",
        "        for images, labels in test_loader:\n",
        "            \n",
        "            # YOUR CODE HERE\n",
        "            # raise NotImplementedError()\n",
        "            '''\n",
        "            YOUR CODE HERE\n",
        "            '''\n",
        "            ## Move the images to the device\n",
        "            images = images.to(device)\n",
        "            ## Move the labels to the device\n",
        "            labels = labels.to(device)\n",
        "            ## Get the output of the model by passing images as input to the model\n",
        "            output = classifier(images)\n",
        "            ## convert the outputs to a probability distribution using softmax and \n",
        "            softmax = torch.exp(output).cpu()\n",
        "            ## find the prediction with maximum probability\n",
        "            prob = list(softmax.numpy())\n",
        "            predictions = np.argmax(prob, axis=1)\n",
        "            ## compare predictions with ground truth for number of correct samples\n",
        "            correct += count_correct(predictions, [label.item() for label in labels])\n",
        "\n",
        "            total_samples += labels.size(0)\n",
        "        \n",
        "        accuracy = (correct/total_samples)*100\n",
        "        print(\"Total Accuracy on the Test set: {} %\".format(accuracy))\n",
        "        return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvjDL832U7ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fee6b51c-6127-44a8-c315-7acacffb21c0"
      },
      "source": [
        "classfier_10, loss_10 = train_model(finetune_loader_10, images_per_class = 10, epochs=100)\n",
        "accuracy_10 = test_model(classfier_10)\n",
        "\n",
        "classfier_100, loss_100 = train_model(finetune_loader_100, images_per_class = 100, epochs=100)\n",
        "accuracy_100 = test_model(classfier_100)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 complete\tTime: 9.2306s\t\tLoss: 2.3334\n",
            "================================================================================\n",
            "Epoch 1 complete\tTime: 9.2306s\t\tLoss: 2.3133\n",
            "================================================================================\n",
            "Total Accuracy on the Test set: 10.639999999999999 %\n",
            "Epoch 0 complete\tTime: 9.2306s\t\tLoss: 18.5542\n",
            "================================================================================\n",
            "Epoch 1 complete\tTime: 9.2306s\t\tLoss: 18.4803\n",
            "================================================================================\n",
            "Total Accuracy on the Test set: 8.84 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}